import os
import streamlit as st
import openai
from googletrans import Translator

# --- 1. SEGURIDAD ---
api_key = os.getenv("OPENAI_API_KEY")

# --- 2. CONFIGURACI√ìN DE PANTALLA ---
st.set_page_config(page_title="AI Trans Pro", page_icon="üåê", layout="centered")

with st.sidebar:
    # Logo y versi√≥n (Limpiamos la redundancia aqu√≠)
    st.image("logo_beta.png", width=150) if os.path.exists("logo_beta.png") else st.title("üåê AI Trans")
    st.info("üöÄ **Versi√≥n Beta v0.5.5**")
    
    # L√≥gica de detecci√≥n de llave
    if api_key and "sk-tu-clave" not in api_key:
        st.success("‚úÖ IA Conectada")
        openai.api_key = api_key
    else:
        st.warning("‚ö†Ô∏è Configura tu API Key Real en Secrets")
        api_key = st.text_input("O introduce Key manualmente:", type="password")
        openai.api_key = api_key

    st.markdown("---")
    motor = st.selectbox("Motor de traducci√≥n:", ["Google (Gratis)", "OpenAI (GPT-4)"])

# --- 3. CUERPO PRINCIPAL ---
st.title("üåê Traductor Pro Multi-Modo")

# Usamos st.session_state para que el texto no se borre al cambiar de pesta√±a
if "texto_a_traducir" not in st.session_state:
    st.session_state.texto_a_traducir = ""

tab1, tab2, tab3 = st.tabs(["‚å®Ô∏è Texto", "üé§ Voz", "üì∏ Imagen"])

with tab1:
    # El √°rea de texto ahora est√° conectada a la memoria de la app
    texto_usuario = st.text_area("Escribe o revisa el audio:", 
                                value=st.session_state.texto_a_traducir, 
                                height=150)

with tab2:
    st.write("### üéôÔ∏è Grabadora de Voz")
    audio_file = st.audio_input("Haz clic para hablar") # El componente de tu captura
    
    if audio_file:
        if st.button("Transcribir Voz ü§ñ"):
            if not api_key or "sk-" not in api_key:
                st.error("Se requiere una API Key real para procesar audio.")
            else:
                try:
                    with st.spinner("Whisper est√° escuchando..."):
                        # Guardar temporalmente el audio
                        with open("temp.wav", "wb") as f:
                            f.write(audio_file.read())
                        
                        # Transcripci√≥n oficial de OpenAI
                        with open("temp.wav", "rb") as audio:
                            transcripcion = openai.audio.transcriptions.create(
                                model="whisper-1", 
                                file=audio
                            )
                        
                        # Guardamos el resultado en la memoria
                        st.session_state.texto_a_traducir = transcripcion.text
                        st.success(f"Texto detectado: {transcripcion.text}")
                        st.rerun() # Refresca para mostrar el texto en la Tab 1
                except Exception as e:
                    st.error(f"Error procesando audio: {e}")

with tab3:
    st.info("üì∏ Visi√≥n Artificial: Pr√≥ximamente.")

# --- 4. ACCI√ìN FINAL ---
idioma_dest = st.selectbox("Idioma destino:", ["Spanish", "English", "French", "German"])

if st.button("TRADUCIR AHORA ‚ú®"):
    # Prioriza el texto que el usuario edit√≥ o el que vino de la voz
    final_text = texto_usuario if texto_usuario else st.session_state.texto_a_traducir
    
    if not final_text:
        st.warning("Escribe algo o graba un audio primero.")
    else:
        with st.spinner('Traduciendo...'):
            try:
                if motor == "Google (Gratis)":
                    res = Translator().translate(final_text, dest=idioma_dest[:2].lower()).text
                else:
                    response = openai.chat.completions.create(
                        model="gpt-4",
                        messages=[{"role": "user", "content": f"Translate to {idioma_dest}: {final_text}"}]
                    )
                    res = response.choices[0].message.content
                st.success(f"### Resultado:\n{res}")
            except Exception as e:
                st.error(f"Error en traducci√≥n: {e}")

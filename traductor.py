import os
import streamlit as st
import openai
from googletrans import Translator

# --- 1. CONFIGURACI√ìN DE SEGURIDAD ---
# Intenta obtener la clave del sistema
api_key = os.getenv("OPENAI_API_KEY")

# --- 2. INTERFAZ Y ESTILO ---
st.set_page_config(page_title="AI Trans Pro", page_icon="üåê", layout="centered")

# Inyectar el manifest para PWA
st.markdown('<link rel="manifest" href="/manifest.json">', unsafe_allow_html=True)

with st.sidebar:
    st.image("logo_beta.png", width=150) if os.path.exists("logo_beta.png") else st.title("üåê AI Trans")
    st.info("üöÄ **Versi√≥n Beta v0.5.2**")
    
    # Si la clave en Secrets es v√°lida (no es la de ejemplo), ocultamos el input
    if api_key and "sk-tu-clave" not in api_key:
        st.success("‚úÖ Sistema: Conectado")
        openai.api_key = api_key
    else:
        st.warning("‚ö†Ô∏è Configura tu API Key Real")
        api_key = st.text_input("OpenAI API Key:", type="password", help="Pega tu clave sk-...")
        openai.api_key = api_key

    st.markdown("---")
    motor = st.selectbox("Motor de traducci√≥n:", ["Google (Gratis)", "OpenAI (GPT-4)"])
    idioma_dest = st.selectbox("Idioma destino:", ["Spanish", "English", "French", "German", "Italian"])

# --- 3. CUERPO DE LA APP ---
st.title("üåê Traductor Pro Multi-Modo")

tab1, tab2, tab3 = st.tabs(["‚å®Ô∏è Texto", "üé§ Voz", "üì∏ Imagen"])

with tab1:
    # Usamos session_state para que el texto de voz aparezca aqu√≠ autom√°ticamente
    if "input_text" not in st.session_state:
        st.session_state.input_text = ""
    
    texto_usuario = st.text_area("Escribe aqu√≠:", value=st.session_state.input_text, height=150)

with tab2:
    st.write("### Asistente de Voz")
    audio_data = st.audio_input("Graba tu mensaje")
    
    if audio_data:
        if st.button("Transcibir Audio üîä"):
            if not api_key or "sk-" not in api_key:
                st.error("Se requiere una API Key real para procesar voz.")
            else:
                try:
                    with st.spinner("Whisper est√° escuchando..."):
                        # Guardar temporalmente
                        with open("temp.wav", "wb") as f:
                            f.write(audio_data.read())
                        
                        # Transcripci√≥n con OpenAI
                        with open("temp.wav", "rb") as f:
                            transcript = openai.audio.transcriptions.create(model="whisper-1", file=f)
                        
                        st.session_state.input_text = transcript.text
                        st.success(f"Texto detectado: {transcript.text}")
                        st.info("Vuelve a la pesta√±a 'Texto' para traducir.")
                except Exception as e:
                    st.error(f"Error de voz: {e}")

with tab3:
    st.info("M√≥dulo de Visi√≥n Artificial: Pr√≥ximamente.")

# --- 4. ACCI√ìN DE TRADUCCI√ìN ---
if st.button("TRADUCIR AHORA ‚ú®"):
    texto_final = st.session_state.input_text if not texto_usuario else texto_usuario
    if not texto_final:
        st.warning("Escribe o graba algo primero.")
    else:
        try:
            with st.spinner('Traduciendo...'):
                if motor == "Google (Gratis)":
                    translator = Translator()
                    resultado = translator.translate(texto_final, dest=idioma_dest[:2].lower()).text
                else:
                    response = openai.chat.completions.create(
                        model="gpt-4",
                        messages=[{"role": "user", "content": f"Translate to {idioma_dest}: {texto_final}"}]
                    )
                    resultado = response.choices[0].message.content
                
                st.success("### Resultado:")
                st.write(resultado)
        except Exception as e:
            st.error(f"Error en traducci√≥n: {e}")

st.markdown("---")
st.caption("Desarrollado por Jonatan Alejandro Flores | Creator Edition")
